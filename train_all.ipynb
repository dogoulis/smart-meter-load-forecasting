{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pantelisdogoulis/miniforge3/envs/energy-forecasting/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# from neuralprophet import NeuralProphet\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import generate_lagged_features, scale_data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from utils import mape, gmrae, smape_adjusted, nrmse\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data.csv'\n",
    "data = pd.read_csv(path, parse_dates=[\"datetime\"])\n",
    "data.set_index('datetime', inplace=True)\n",
    "data[\"AP\"] = data[\"AP\"].astype(\"category\")\n",
    "data[\"AP\"] = data[\"AP\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAGS = 5\n",
    "N_FORECASTS = 4 # (FORECASTS-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = [f'lag{i}' for i in range(N_FORECASTS+1,N_FORECASTS+1+N_LAGS)]\n",
    "X_features.reverse()\n",
    "y_features = [f'lag{i}' for i in range(0, N_FORECASTS+1)]\n",
    "y_features.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3910/3910 [15:31<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "lagged_df = pd.DataFrame()\n",
    "\n",
    "for customer_id in tqdm(data.AP.unique()):\n",
    "    customer = data[data['AP']==customer_id]\n",
    "    generate_lagged_features(data, 'ENERGY', N_LAGS + N_FORECASTS)\n",
    "    customer.dropna(inplace=True)\n",
    "    lagged_df = pd.concat((lagged_df, customer))\n",
    "lagged_df = lagged_df.rename(columns={\n",
    "                            'scaled':'lag0',})\n",
    "lagged_df = lagged_df.rename(columns={'ENERGY_MW': 'lag0'})\n",
    "lagged_df.dropna(inplace=True)\n",
    "\n",
    "test = lagged_df[lagged_df.index==2021]\n",
    "train = lagged_df[lagged_df.index.isin([2015,2016,2017,2018,2019,2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df.to_csv(\"./data/lagged_df_kw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lagged_df[lagged_df.index.year==2021]\n",
    "train = lagged_df[lagged_df.index.year.isin([2015,2016,2017,2018,2019,2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mean'] = train[X_features].mean(axis=1)\n",
    "train['std'] = train[X_features].std(axis=1)\n",
    "train['skew'] = train[X_features].skew(axis=1)\n",
    "train['kurtosis'] = train[X_features].kurtosis(axis=1)\n",
    "\n",
    "test['mean'] = test[X_features].mean(axis=1)\n",
    "test['std'] = test[X_features].std(axis=1)\n",
    "test['skew'] = test[X_features].skew(axis=1)\n",
    "test['kurtosis'] = test[X_features].kurtosis(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_features = ['AP', 'mean', 'std', 'skew', 'sin_dayofyear', 'cos_dayofyear', 'sin_month', 'cos_month', 'sin_week', 'cos_week', 'sin_season', 'cos_season'] \n",
    "X_features.extend(ad_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n"
     ]
    }
   ],
   "source": [
    "# TRAIN:\n",
    "\n",
    "X_train = train[X_features]\n",
    "y_train = train[y_features]\n",
    "\n",
    "# hyperparameter tuning\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "reg = MultiOutputRegressor(LGBMRegressor(n_estimators=400, max_depth=8, min_child_samples=20, reg_lambda=0.1, min_split_gain=20, num_leaves=31))\n",
    "params = dict(estimator__n_estimators=[500,1000], estimator__max_depth=[5,12,20], \\\n",
    "  estimator__min_child_samples=[20,50,100], estimator__min_split_gain=[10,20,40], estimator__num_leaves=[30,40])\n",
    "gs = RandomizedSearchCV(estimator=reg, param_distributions=params, cv=tscv, random_state=42)\n",
    "# fitting\n",
    "gs.fit(X_train,  y_train)\n",
    "# selecting best estimator \n",
    "reg = gs.best_estimator_\n",
    "\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3910/3910 [01:01<00:00, 63.10it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "y_pred_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for customer_id in tqdm(test.AP.unique()):\n",
    "    customer_test = test[test['AP']==customer_id]\n",
    "\n",
    "    customer_test['mean'] = customer_test[X_features].mean(axis=1)\n",
    "    customer_test['std'] = customer_test[X_features].std(axis=1)\n",
    "    customer_test['skew'] = customer_test[X_features].skew(axis=1)\n",
    "    customer_test['kurtosis'] = customer_test[X_features].kurtosis(axis=1)\n",
    "\n",
    "    X_test = customer_test[X_features]\n",
    "    y_test = customer_test[y_features]\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # y_pred = pd.DataFrame(y_pred)\n",
    "    # y_pred.columns = y_features\n",
    "    # y_pred.index = y_test.index\n",
    "\n",
    "    # NAIVE\n",
    "    y_naive = pd.DataFrame(X_test[['lag5']*5])\n",
    "    y_naive.index = X_test.index\n",
    "    y_naive.columns = y_test.columns\n",
    "    \n",
    "    mse = mean_squared_error(y_test.values, y_pred)\n",
    "    mae = mean_absolute_error(y_test.values, y_pred)\n",
    "    mape_sk = mean_absolute_percentage_error(y_test.values, y_pred)\n",
    "    r_sq = r2_score(y_test.values, y_pred)\n",
    "    # nrmse_value = nrmse(y_test.values, y_pred.values, y_naive.values)\n",
    "    mape_value = np.mean(mape(y_test.values, y_pred))\n",
    "    smape_value = np.mean(smape_adjusted(y_test.values, y_pred))\n",
    "    nrmae_value = mean_absolute_error(y_test, y_pred) / mean_absolute_error(y_test, y_naive)\n",
    "    # mape_value = mape(y_test.values, y_pred.values)\n",
    "    # gmrae_value = gmrae(y_test.values, y_pred.values, naive.values)\n",
    "    # smape_value = smape_adjusted(y_test.values, y_pred.values)\n",
    "\n",
    "    metrics = np.concatenate((np.reshape(customer_id, (1,1)),np.reshape(mse, (1,1)), \\\n",
    "    np.reshape(mae, (1,1)), np.reshape(mape_sk, (1,1)), np.reshape(r_sq, (1,1)),\\\n",
    "    np.reshape(mape_value, (1,1)), np.reshape(smape_value, (1,1)), np.reshape(nrmae_value, (1,1)) ), axis=1)\n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    metrics.columns = ['AP', 'mse', 'mae', 'mape_sk', 'r_sq', 'mape', 'smape', 'nrmae']\n",
    "\n",
    "    metrics_df = pd.concat((metrics_df, metrics), axis=0)\n",
    "    \n",
    "    customer_id_array = np.full((39,1), customer_id)\n",
    "    y_pred = np.concatenate((y_pred, customer_id_array),1)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    y_pred.columns = ['lag4', 'lag3', 'lag2', 'lag1', 'lag0', 'AP']\n",
    "    y_pred.index = y_test.index\n",
    "\n",
    "    y_pred_df = pd.concat((y_pred_df, y_pred), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('energy-forecasting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "636d45089a604176c9445f6baf324426a17f89b7d72c9fa489ff4cf02b784dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
