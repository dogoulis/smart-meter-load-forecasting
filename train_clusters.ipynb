{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pantelisdogoulis/miniforge3/envs/energy-forecasting/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# from neuralprophet import NeuralProphet\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import generate_lagged_features, scale_data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from utils import mape, gmrae, smape_adjusted, nrmse\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df = pd.read_csv(\"lagged_df_kw.csv\", parse_dates=[\"datetime\"])\n",
    "lagged_df.set_index('datetime', inplace=True)\n",
    "lagged_df[\"AP\"] = lagged_df[\"AP\"].astype(\"category\")\n",
    "lagged_df[\"AP\"] = lagged_df[\"AP\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lagged_df[lagged_df.index.year==2021]\n",
    "train = lagged_df[lagged_df.index.year.isin([2015,2016,2017,2018,2019,2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAGS = 5\n",
    "N_FORECASTS = 4 # (FORECASTS-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = [f'lag{i}' for i in range(N_FORECASTS+1,N_FORECASTS+1+N_LAGS)]\n",
    "y_features = [f'lag{i}' for i in range(0, N_FORECASTS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [00:06<00:00, 222.51it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 213.47it/s]\n",
      "100%|██████████| 820/820 [00:04<00:00, 204.74it/s]\n",
      "100%|██████████| 201/201 [00:01<00:00, 194.22it/s]\n",
      "100%|██████████| 201/201 [00:01<00:00, 198.25it/s]\n",
      "100%|██████████| 899/899 [00:04<00:00, 190.51it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 146.28it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 157.68it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 137.30it/s]\n",
      "100%|██████████| 9/9 [01:18<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "y_pred_df = pd.DataFrame()\n",
    "\n",
    "for cluster in tqdm(lagged_df.clusters.unique()):\n",
    "\n",
    "    X_features = [f'lag{i}' for i in range(N_FORECASTS+1,N_FORECASTS+1+N_LAGS)]\n",
    "\n",
    "    # TRAIN:\n",
    "    train_cluster = train[train['clusters']==cluster]\n",
    "    train_cluster['mean'] = train_cluster[X_features].mean(axis=1)\n",
    "    train_cluster['std'] = train_cluster[X_features].std(axis=1)\n",
    "    train_cluster['skew'] = train_cluster[X_features].skew(axis=1)\n",
    "    train_cluster['kurtosis'] = train_cluster[X_features].kurtosis(axis=1)\n",
    "    train_cluster['max'] = train_cluster[X_features].max(axis=1)\n",
    "    train_cluster['min'] = train_cluster[X_features].min(axis=1)\n",
    "    train_cluster['mean'] = train_cluster[X_features].mean(axis=1)\n",
    "    # train_cluster['mean_last_2'] = train_cluster[['lag6', 'lag5']].mean(axis=1)\n",
    "    # train_cluster['mean_past_2'] = train_cluster[['lag9', 'lag8']].mean(axis=1)\n",
    "    train_cluster['std'] = train_cluster[X_features].std(axis=1)\n",
    "    train_cluster['var'] = train_cluster[X_features].var(axis=1)\n",
    "\n",
    "\n",
    "    # PREDICT\n",
    "    test_cluster = test[test['clusters']==cluster]\n",
    "    \n",
    "    test_cluster['max'] = test_cluster[X_features].max(axis=1)\n",
    "    test_cluster['min'] = test_cluster[X_features].min(axis=1)\n",
    "    test_cluster['mean'] = test_cluster[X_features].mean(axis=1)\n",
    "    # test_cluster['mean_last_2'] = test_cluster[['lag6', 'lag5']].mean(axis=1)\n",
    "    # test_cluster['mean_past_2'] = test_cluster[['lag9', 'lag8']].mean(axis=1)\n",
    "    test_cluster['std'] = test_cluster[X_features].std(axis=1)\n",
    "    test_cluster['skew'] = test_cluster[X_features].skew(axis=1)\n",
    "    test_cluster['kurtosis'] = test_cluster[X_features].kurtosis(axis=1)\n",
    "    test_cluster['var'] = test_cluster[X_features].var(axis=1)\n",
    "\n",
    "    ad_features = ['mean', 'min','std', 'skew', 'kurtosis','sin_month', 'cos_month', 'sin_dayofyear', 'cos_dayofyear', 'sin_week',\n",
    "       'cos_week', 'max'] \n",
    "    X_features.extend(ad_features)\n",
    "\n",
    "    X_train = train_cluster[X_features]\n",
    "    y_train = train_cluster[y_features]\n",
    "\n",
    "    # reg = MultiOutputRegressor(LGBMRegressor(n_estimators=400, max_depth=8, min_child_samples=20, reg_lambda=0.1, min_split_gain=20, num_leaves=31))\n",
    "    reg = ElasticNet()\n",
    "    reg.fit(X_train,  y_train)\n",
    "\n",
    "    # PREDICT\n",
    "\n",
    "    for customer_id in tqdm(test_cluster.AP.unique()):\n",
    "            \n",
    "        customer_cluster = test_cluster[test_cluster['AP']==customer_id]\n",
    "        X_test = customer_cluster[X_features]\n",
    "        y_test = customer_cluster[y_features]\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        y_pred = pd.DataFrame(y_pred)\n",
    "        y_pred.columns = y_features\n",
    "\n",
    "        # NAIVE\n",
    "        y_naive = pd.DataFrame(X_test[['lag5']*5])\n",
    "        y_naive.index = X_test.index\n",
    "        y_naive.columns = y_test.columns\n",
    "\n",
    "\n",
    "        # metrics\n",
    "    \n",
    "        mse = mean_squared_error(y_test.values, y_pred)\n",
    "        mae = mean_absolute_error(y_test.values, y_pred)\n",
    "        mape_sk = mean_absolute_percentage_error(y_test.values, y_pred)\n",
    "        r_sq = r2_score(y_test.values, y_pred)\n",
    "        nrmae = mean_absolute_error(y_test, y_pred) / mean_absolute_error(y_test, y_naive)\n",
    "        mape_value = np.mean(mape(y_test.values, y_pred))\n",
    "        smape_value = np.mean(smape_adjusted(y_test.values, y_pred))\n",
    "        # mape_value = mape(y_test.values, y_pred.values)\n",
    "        # gmrae_value = gmrae(y_test.values, y_pred.values, naive.values)\n",
    "        # smape_value = smape_adjusted(y_test.values, y_pred.values)\n",
    "\n",
    "        metrics = np.concatenate((np.reshape(customer_id, (1,1)),np.reshape(mse, (1,1)), \\\n",
    "        np.reshape(mae, (1,1)), np.reshape(mape_sk, (1,1)), np.reshape(r_sq, (1,1)),\\\n",
    "        np.reshape(mape_value, (1,1)), np.reshape(smape_value, (1,1)), np.reshape(nrmae, (1,1)) ), axis=1)\n",
    "        metrics = pd.DataFrame(metrics)\n",
    "        metrics.columns = ['AP', 'mse', 'mae', 'mape_sk', 'r_sq', 'mape', 'smape', 'nrmae']\n",
    "\n",
    "        metrics_df = pd.concat((metrics_df, metrics), axis=0)\n",
    "        \n",
    "        customer_id_array = np.full((39,1), customer_id)\n",
    "        y_pred = np.concatenate((y_pred, customer_id_array),1)\n",
    "        y_pred = pd.DataFrame(y_pred)\n",
    "        y_pred.columns = ['lag4', 'lag3', 'lag2', 'lag1', 'lag0', 'AP']\n",
    "        y_pred.index = y_test.index\n",
    "\n",
    "        y_pred_df = pd.concat((y_pred_df, y_pred), axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('energy-forecasting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "636d45089a604176c9445f6baf324426a17f89b7d72c9fa489ff4cf02b784dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
